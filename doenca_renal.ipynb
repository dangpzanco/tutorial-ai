{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doença Renal Crônica\n",
    "\n",
    "## Classifying patients as having chronic kidney disease or not using Artificial Neural Networks\n",
    "\n",
    "### Referência: [Chronic Kidney Disease Prediction Using Python & Machine Learning](https://medium.com/@randerson112358/chronic-kidney-disease-prediction-detection-using-machine-learning-29cc7e3eba96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>7800</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>6700</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>7300</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>7800</td>\n",
       "      <td>4.4</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>68.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>6900</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>52.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>9600</td>\n",
       "      <td>4.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>53.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>12100</td>\n",
       "      <td>3.7</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age     bp     sg   al   su       rbc        pc         pcc  \\\n",
       "0   0  48.0   80.0  1.020  1.0  0.0       NaN    normal  notpresent   \n",
       "1   1   7.0   50.0  1.020  4.0  0.0       NaN    normal  notpresent   \n",
       "2   2  62.0   80.0  1.010  2.0  3.0    normal    normal  notpresent   \n",
       "3   3  48.0   70.0  1.005  4.0  0.0    normal  abnormal     present   \n",
       "4   4  51.0   80.0  1.010  2.0  0.0    normal    normal  notpresent   \n",
       "5   5  60.0   90.0  1.015  3.0  0.0       NaN       NaN  notpresent   \n",
       "6   6  68.0   70.0  1.010  0.0  0.0       NaN    normal  notpresent   \n",
       "7   7  24.0    NaN  1.015  2.0  4.0    normal  abnormal  notpresent   \n",
       "8   8  52.0  100.0  1.015  3.0  0.0    normal  abnormal     present   \n",
       "9   9  53.0   90.0  1.020  2.0  0.0  abnormal  abnormal     present   \n",
       "\n",
       "           ba  ...  pcv     wc   rc  htn   dm  cad appet   pe  ane  \\\n",
       "0  notpresent  ...   44   7800  5.2  yes  yes   no  good   no   no   \n",
       "1  notpresent  ...   38   6000  NaN   no   no   no  good   no   no   \n",
       "2  notpresent  ...   31   7500  NaN   no  yes   no  poor   no  yes   \n",
       "3  notpresent  ...   32   6700  3.9  yes   no   no  poor  yes  yes   \n",
       "4  notpresent  ...   35   7300  4.6   no   no   no  good   no   no   \n",
       "5  notpresent  ...   39   7800  4.4  yes  yes   no  good  yes   no   \n",
       "6  notpresent  ...   36    NaN  NaN   no   no   no  good   no   no   \n",
       "7  notpresent  ...   44   6900    5   no  yes   no  good  yes   no   \n",
       "8  notpresent  ...   33   9600  4.0  yes  yes   no  good   no  yes   \n",
       "9  notpresent  ...   29  12100  3.7  yes  yes   no  poor   no  yes   \n",
       "\n",
       "  classification  \n",
       "0            ckd  \n",
       "1            ckd  \n",
       "2            ckd  \n",
       "3            ckd  \n",
       "4            ckd  \n",
       "5            ckd  \n",
       "6            ckd  \n",
       "7            ckd  \n",
       "8            ckd  \n",
       "9            ckd  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data \n",
    " \n",
    "df = pd.read_csv('kidney_disease.csv')\n",
    "    \n",
    "#Print the first 10 rows\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 26)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the shape of the data (the number of rows & columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description:\n",
    "- **sg** - specific gravity\n",
    "- **al** - albumin\n",
    "- **sc** - serum creatinine\n",
    "- **hemo** - hemoglobin\n",
    "- **pcv** - packed cell volume\n",
    "- **wc**\t-\twhite blood cell count \n",
    "- **rc**\t-\tred blood cell count \n",
    "- **htn** - hypertension\n",
    "- **class** - class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation: Clean The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of columns to retain\n",
    "columns_to_retain = [\"age\",\"sg\", \"al\", \"sc\", \"hemo\", \"pcv\", \"wc\", \"rc\", \"htn\", \"classification\"]\n",
    "\n",
    "# Only keep the columns that are in columns_to_retain\n",
    "df = df[columns_to_retain]\n",
    "    \n",
    "# Drop the rows with na or missing values\n",
    "df = df.dropna(axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>sc</th>\n",
       "      <th>hemo</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>44</td>\n",
       "      <td>7800</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>32</td>\n",
       "      <td>6700</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>11.6</td>\n",
       "      <td>35</td>\n",
       "      <td>7300</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>12.2</td>\n",
       "      <td>39</td>\n",
       "      <td>7800</td>\n",
       "      <td>4.4</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>44</td>\n",
       "      <td>6900</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>33</td>\n",
       "      <td>9600</td>\n",
       "      <td>4.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>29</td>\n",
       "      <td>12100</td>\n",
       "      <td>3.7</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>10.8</td>\n",
       "      <td>32</td>\n",
       "      <td>4500</td>\n",
       "      <td>3.8</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>9.7</td>\n",
       "      <td>28</td>\n",
       "      <td>12200</td>\n",
       "      <td>3.4</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>16</td>\n",
       "      <td>11000</td>\n",
       "      <td>2.6</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age     sg   al   sc  hemo pcv     wc   rc  htn classification\n",
       "0   48.0  1.020  1.0  1.2  15.4  44   7800  5.2  yes            ckd\n",
       "3   48.0  1.005  4.0  3.8  11.2  32   6700  3.9  yes            ckd\n",
       "4   51.0  1.010  2.0  1.4  11.6  35   7300  4.6   no            ckd\n",
       "5   60.0  1.015  3.0  1.1  12.2  39   7800  4.4  yes            ckd\n",
       "7   24.0  1.015  2.0  1.1  12.4  44   6900    5   no            ckd\n",
       "8   52.0  1.015  3.0  1.9  10.8  33   9600  4.0  yes            ckd\n",
       "9   53.0  1.020  2.0  7.2   9.5  29  12100  3.7  yes            ckd\n",
       "11  63.0  1.010  3.0  2.7  10.8  32   4500  3.8  yes            ckd\n",
       "12  68.0  1.015  3.0  2.1   9.7  28  12200  3.4  yes            ckd\n",
       "14  68.0  1.010  3.0  4.1   5.6  16  11000  2.6  yes            ckd"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the first 5 rows\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform non-numeric columns into numerical columns\n",
    "for column in df.columns:\n",
    "        if df[column].dtype == np.number:\n",
    "            continue\n",
    "        df[column] = LabelEncoder().fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>sc</th>\n",
       "      <th>hemo</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>26</td>\n",
       "      <td>65</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>14</td>\n",
       "      <td>55</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>11.6</td>\n",
       "      <td>17</td>\n",
       "      <td>61</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>12.2</td>\n",
       "      <td>21</td>\n",
       "      <td>65</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>26</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.7</td>\n",
       "      <td>29</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>16.5</td>\n",
       "      <td>36</td>\n",
       "      <td>65</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15.8</td>\n",
       "      <td>31</td>\n",
       "      <td>54</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>33</td>\n",
       "      <td>60</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>15.8</td>\n",
       "      <td>35</td>\n",
       "      <td>56</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sg   al   sc  hemo  pcv  wc  rc  htn  classification\n",
       "0    48.0  1.020  1.0  1.2  15.4   26  65  30    1               0\n",
       "3    48.0  1.005  4.0  3.8  11.2   14  55  15    1               0\n",
       "4    51.0  1.010  2.0  1.4  11.6   17  61  23    0               0\n",
       "5    60.0  1.015  3.0  1.1  12.2   21  65  21    1               0\n",
       "7    24.0  1.015  2.0  1.1  12.4   26  57  27    0               0\n",
       "..    ...    ...  ...  ...   ...  ...  ..  ..  ...             ...\n",
       "395  55.0  1.020  0.0  0.5  15.7   29  55  26    0               1\n",
       "396  42.0  1.025  0.0  1.2  16.5   36  65  40    0               1\n",
       "397  12.0  1.020  0.0  0.6  15.8   31  54  32    0               1\n",
       "398  17.0  1.025  0.0  1.0  14.2   33  60  37    0               1\n",
       "399  58.0  1.025  0.0  1.1  15.8   35  56  39    0               1\n",
       "\n",
       "[236 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation: Split & Scale The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = df.drop([\"classification\"], axis=1)\n",
    "y = df[\"classification\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "x_scaler = MinMaxScaler()\n",
    "x_scaler.fit(X)\n",
    "column_names = X.columns\n",
    "X[column_names] = x_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into 90% training and 10% testing\n",
    "X_train,  X_test, y_train, y_test = train_test_split(X, y, test_size= 0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build The Model (Artificial Neural Network):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build The model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=len(X.columns), activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"hard_sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               1280      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,409\n",
      "Trainable params: 1,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 212 samples, validate on 24 samples\n",
      "Epoch 1/500\n",
      "212/212 [==============================] - 2s 7ms/sample - loss: 0.6742 - accuracy: 0.5472 - val_loss: 0.6540 - val_accuracy: 0.5833\n",
      "Epoch 2/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.6672 - accuracy: 0.5472 - val_loss: 0.6468 - val_accuracy: 0.5833\n",
      "Epoch 3/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.6601 - accuracy: 0.5472 - val_loss: 0.6397 - val_accuracy: 0.5833\n",
      "Epoch 4/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.6532 - accuracy: 0.5472 - val_loss: 0.6328 - val_accuracy: 0.5833\n",
      "Epoch 5/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.6464 - accuracy: 0.5472 - val_loss: 0.6259 - val_accuracy: 0.5833\n",
      "Epoch 6/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.6396 - accuracy: 0.5519 - val_loss: 0.6190 - val_accuracy: 0.5833\n",
      "Epoch 7/500\n",
      "212/212 [==============================] - 0s 35us/sample - loss: 0.6330 - accuracy: 0.5660 - val_loss: 0.6122 - val_accuracy: 0.5833\n",
      "Epoch 8/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.6264 - accuracy: 0.5708 - val_loss: 0.6055 - val_accuracy: 0.6250\n",
      "Epoch 9/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.6198 - accuracy: 0.5849 - val_loss: 0.5989 - val_accuracy: 0.6250\n",
      "Epoch 10/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.6134 - accuracy: 0.5991 - val_loss: 0.5924 - val_accuracy: 0.6250\n",
      "Epoch 11/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.6070 - accuracy: 0.6038 - val_loss: 0.5859 - val_accuracy: 0.6667\n",
      "Epoch 12/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.6006 - accuracy: 0.6368 - val_loss: 0.5796 - val_accuracy: 0.7083\n",
      "Epoch 13/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.5943 - accuracy: 0.6462 - val_loss: 0.5732 - val_accuracy: 0.7500\n",
      "Epoch 14/500\n",
      "212/212 [==============================] - 0s 37us/sample - loss: 0.5880 - accuracy: 0.6509 - val_loss: 0.5669 - val_accuracy: 0.7917\n",
      "Epoch 15/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.5817 - accuracy: 0.6604 - val_loss: 0.5606 - val_accuracy: 0.7917\n",
      "Epoch 16/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.5755 - accuracy: 0.6792 - val_loss: 0.5543 - val_accuracy: 0.7917\n",
      "Epoch 17/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.5692 - accuracy: 0.6887 - val_loss: 0.5480 - val_accuracy: 0.7917\n",
      "Epoch 18/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.5630 - accuracy: 0.7123 - val_loss: 0.5417 - val_accuracy: 0.7917\n",
      "Epoch 19/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.5568 - accuracy: 0.7311 - val_loss: 0.5354 - val_accuracy: 0.7917\n",
      "Epoch 20/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.5507 - accuracy: 0.7453 - val_loss: 0.5291 - val_accuracy: 0.7917\n",
      "Epoch 21/500\n",
      "212/212 [==============================] - 0s 29us/sample - loss: 0.5445 - accuracy: 0.7453 - val_loss: 0.5228 - val_accuracy: 0.7917\n",
      "Epoch 22/500\n",
      "212/212 [==============================] - 0s 31us/sample - loss: 0.5384 - accuracy: 0.7547 - val_loss: 0.5164 - val_accuracy: 0.7917\n",
      "Epoch 23/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.5322 - accuracy: 0.7736 - val_loss: 0.5100 - val_accuracy: 0.7917\n",
      "Epoch 24/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.5261 - accuracy: 0.7783 - val_loss: 0.5037 - val_accuracy: 0.7917\n",
      "Epoch 25/500\n",
      "212/212 [==============================] - 0s 44us/sample - loss: 0.5200 - accuracy: 0.7877 - val_loss: 0.4974 - val_accuracy: 0.7917\n",
      "Epoch 26/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.5138 - accuracy: 0.7925 - val_loss: 0.4910 - val_accuracy: 0.8333\n",
      "Epoch 27/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.5077 - accuracy: 0.8113 - val_loss: 0.4847 - val_accuracy: 0.8333\n",
      "Epoch 28/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.5016 - accuracy: 0.8113 - val_loss: 0.4784 - val_accuracy: 0.8333\n",
      "Epoch 29/500\n",
      "212/212 [==============================] - 0s 36us/sample - loss: 0.4955 - accuracy: 0.8255 - val_loss: 0.4721 - val_accuracy: 0.8333\n",
      "Epoch 30/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.4894 - accuracy: 0.8302 - val_loss: 0.4658 - val_accuracy: 0.8333\n",
      "Epoch 31/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.4834 - accuracy: 0.8349 - val_loss: 0.4595 - val_accuracy: 0.8750\n",
      "Epoch 32/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.4773 - accuracy: 0.8538 - val_loss: 0.4533 - val_accuracy: 0.8750\n",
      "Epoch 33/500\n",
      "212/212 [==============================] - 0s 32us/sample - loss: 0.4712 - accuracy: 0.8679 - val_loss: 0.4470 - val_accuracy: 0.8750\n",
      "Epoch 34/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.4651 - accuracy: 0.8726 - val_loss: 0.4406 - val_accuracy: 0.8750\n",
      "Epoch 35/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.4590 - accuracy: 0.8726 - val_loss: 0.4343 - val_accuracy: 0.8750\n",
      "Epoch 36/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.4529 - accuracy: 0.8774 - val_loss: 0.4279 - val_accuracy: 0.8750\n",
      "Epoch 37/500\n",
      "212/212 [==============================] - 0s 26us/sample - loss: 0.4468 - accuracy: 0.8774 - val_loss: 0.4216 - val_accuracy: 0.8750\n",
      "Epoch 38/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.4406 - accuracy: 0.8821 - val_loss: 0.4152 - val_accuracy: 0.8750\n",
      "Epoch 39/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.4345 - accuracy: 0.8821 - val_loss: 0.4088 - val_accuracy: 0.8750\n",
      "Epoch 40/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.4283 - accuracy: 0.8821 - val_loss: 0.4023 - val_accuracy: 0.8750\n",
      "Epoch 41/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.4221 - accuracy: 0.8821 - val_loss: 0.3959 - val_accuracy: 0.8750\n",
      "Epoch 42/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.4159 - accuracy: 0.8821 - val_loss: 0.3895 - val_accuracy: 0.8750\n",
      "Epoch 43/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.4096 - accuracy: 0.8821 - val_loss: 0.3831 - val_accuracy: 0.9167\n",
      "Epoch 44/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.4033 - accuracy: 0.8821 - val_loss: 0.3767 - val_accuracy: 0.9167\n",
      "Epoch 45/500\n",
      "212/212 [==============================] - 0s 37us/sample - loss: 0.3971 - accuracy: 0.8821 - val_loss: 0.3702 - val_accuracy: 0.9167\n",
      "Epoch 46/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.3908 - accuracy: 0.8821 - val_loss: 0.3636 - val_accuracy: 0.9167\n",
      "Epoch 47/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.3845 - accuracy: 0.8821 - val_loss: 0.3571 - val_accuracy: 0.9167\n",
      "Epoch 48/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.3782 - accuracy: 0.8821 - val_loss: 0.3505 - val_accuracy: 0.9167\n",
      "Epoch 49/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.3718 - accuracy: 0.8821 - val_loss: 0.3439 - val_accuracy: 0.9167\n",
      "Epoch 50/500\n",
      "212/212 [==============================] - 0s 37us/sample - loss: 0.3654 - accuracy: 0.8821 - val_loss: 0.3372 - val_accuracy: 0.9167\n",
      "Epoch 51/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.3591 - accuracy: 0.8821 - val_loss: 0.3306 - val_accuracy: 0.9167\n",
      "Epoch 52/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.3527 - accuracy: 0.8821 - val_loss: 0.3240 - val_accuracy: 0.9167\n",
      "Epoch 53/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.3463 - accuracy: 0.8821 - val_loss: 0.3174 - val_accuracy: 0.9167\n",
      "Epoch 54/500\n",
      "212/212 [==============================] - 0s 37us/sample - loss: 0.3399 - accuracy: 0.8868 - val_loss: 0.3108 - val_accuracy: 0.9167\n",
      "Epoch 55/500\n",
      "212/212 [==============================] - 0s 32us/sample - loss: 0.3334 - accuracy: 0.8868 - val_loss: 0.3041 - val_accuracy: 0.9167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "212/212 [==============================] - 0s 56us/sample - loss: 0.3270 - accuracy: 0.8915 - val_loss: 0.2975 - val_accuracy: 0.9167\n",
      "Epoch 57/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.3205 - accuracy: 0.8915 - val_loss: 0.2907 - val_accuracy: 0.9167\n",
      "Epoch 58/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.3141 - accuracy: 0.8915 - val_loss: 0.2840 - val_accuracy: 0.9167\n",
      "Epoch 59/500\n",
      "212/212 [==============================] - 0s 40us/sample - loss: 0.3077 - accuracy: 0.8915 - val_loss: 0.2772 - val_accuracy: 0.9167\n",
      "Epoch 60/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.3013 - accuracy: 0.8962 - val_loss: 0.2705 - val_accuracy: 0.9167\n",
      "Epoch 61/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.2949 - accuracy: 0.8962 - val_loss: 0.2639 - val_accuracy: 0.9167\n",
      "Epoch 62/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.2884 - accuracy: 0.8962 - val_loss: 0.2574 - val_accuracy: 0.9167\n",
      "Epoch 63/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.2820 - accuracy: 0.8962 - val_loss: 0.2515 - val_accuracy: 0.9167\n",
      "Epoch 64/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.2757 - accuracy: 0.8962 - val_loss: 0.2455 - val_accuracy: 0.9167\n",
      "Epoch 65/500\n",
      "212/212 [==============================] - 0s 71us/sample - loss: 0.2693 - accuracy: 0.8962 - val_loss: 0.2395 - val_accuracy: 0.9167\n",
      "Epoch 66/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.2630 - accuracy: 0.9009 - val_loss: 0.2335 - val_accuracy: 0.9167\n",
      "Epoch 67/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.2568 - accuracy: 0.9057 - val_loss: 0.2275 - val_accuracy: 0.9167\n",
      "Epoch 68/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.2508 - accuracy: 0.9104 - val_loss: 0.2216 - val_accuracy: 0.9167\n",
      "Epoch 69/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.2450 - accuracy: 0.9151 - val_loss: 0.2158 - val_accuracy: 0.9167\n",
      "Epoch 70/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.2394 - accuracy: 0.9198 - val_loss: 0.2100 - val_accuracy: 0.9167\n",
      "Epoch 71/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.2338 - accuracy: 0.9245 - val_loss: 0.2043 - val_accuracy: 0.9167\n",
      "Epoch 72/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.2285 - accuracy: 0.9245 - val_loss: 0.1987 - val_accuracy: 0.9167\n",
      "Epoch 73/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.2232 - accuracy: 0.9245 - val_loss: 0.1931 - val_accuracy: 0.9167\n",
      "Epoch 74/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.2181 - accuracy: 0.9245 - val_loss: 0.1877 - val_accuracy: 0.9167\n",
      "Epoch 75/500\n",
      "212/212 [==============================] - 0s 40us/sample - loss: 0.2132 - accuracy: 0.9245 - val_loss: 0.1825 - val_accuracy: 0.9167\n",
      "Epoch 76/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.2085 - accuracy: 0.9245 - val_loss: 0.1773 - val_accuracy: 0.9167\n",
      "Epoch 77/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.2041 - accuracy: 0.9245 - val_loss: 0.1724 - val_accuracy: 0.9167\n",
      "Epoch 78/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.1998 - accuracy: 0.9245 - val_loss: 0.1676 - val_accuracy: 0.9167\n",
      "Epoch 79/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.1956 - accuracy: 0.9245 - val_loss: 0.1631 - val_accuracy: 0.9167\n",
      "Epoch 80/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.1916 - accuracy: 0.9245 - val_loss: 0.1591 - val_accuracy: 0.9167\n",
      "Epoch 81/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.1878 - accuracy: 0.9245 - val_loss: 0.1554 - val_accuracy: 0.9167\n",
      "Epoch 82/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.1841 - accuracy: 0.9245 - val_loss: 0.1521 - val_accuracy: 0.9167\n",
      "Epoch 83/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.1806 - accuracy: 0.9245 - val_loss: 0.1490 - val_accuracy: 0.9167\n",
      "Epoch 84/500\n",
      "212/212 [==============================] - 0s 39us/sample - loss: 0.1771 - accuracy: 0.9245 - val_loss: 0.1458 - val_accuracy: 0.9167\n",
      "Epoch 85/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.1738 - accuracy: 0.9245 - val_loss: 0.1427 - val_accuracy: 0.9167\n",
      "Epoch 86/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.1707 - accuracy: 0.9245 - val_loss: 0.1397 - val_accuracy: 0.9167\n",
      "Epoch 87/500\n",
      "212/212 [==============================] - 0s 31us/sample - loss: 0.1677 - accuracy: 0.9245 - val_loss: 0.1367 - val_accuracy: 0.9167\n",
      "Epoch 88/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.1648 - accuracy: 0.9245 - val_loss: 0.1338 - val_accuracy: 0.9167\n",
      "Epoch 89/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.1620 - accuracy: 0.9292 - val_loss: 0.1311 - val_accuracy: 0.9167\n",
      "Epoch 90/500\n",
      "212/212 [==============================] - 0s 43us/sample - loss: 0.1592 - accuracy: 0.9292 - val_loss: 0.1283 - val_accuracy: 0.9167\n",
      "Epoch 91/500\n",
      "212/212 [==============================] - 0s 44us/sample - loss: 0.1566 - accuracy: 0.9292 - val_loss: 0.1260 - val_accuracy: 0.9167\n",
      "Epoch 92/500\n",
      "212/212 [==============================] - 0s 41us/sample - loss: 0.1540 - accuracy: 0.9292 - val_loss: 0.1238 - val_accuracy: 0.9167\n",
      "Epoch 93/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.1516 - accuracy: 0.9340 - val_loss: 0.1216 - val_accuracy: 0.9167\n",
      "Epoch 94/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.1492 - accuracy: 0.9340 - val_loss: 0.1197 - val_accuracy: 0.9167\n",
      "Epoch 95/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.1470 - accuracy: 0.9340 - val_loss: 0.1179 - val_accuracy: 0.9167\n",
      "Epoch 96/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.1449 - accuracy: 0.9387 - val_loss: 0.1161 - val_accuracy: 0.9167\n",
      "Epoch 97/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.1429 - accuracy: 0.9387 - val_loss: 0.1144 - val_accuracy: 0.9167\n",
      "Epoch 98/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.1409 - accuracy: 0.9387 - val_loss: 0.1127 - val_accuracy: 0.9167\n",
      "Epoch 99/500\n",
      "212/212 [==============================] - 0s 52us/sample - loss: 0.1391 - accuracy: 0.9434 - val_loss: 0.1114 - val_accuracy: 0.9167\n",
      "Epoch 100/500\n",
      "212/212 [==============================] - 0s 34us/sample - loss: 0.1373 - accuracy: 0.9434 - val_loss: 0.1100 - val_accuracy: 0.9167\n",
      "Epoch 101/500\n",
      "212/212 [==============================] - 0s 37us/sample - loss: 0.1356 - accuracy: 0.9434 - val_loss: 0.1087 - val_accuracy: 0.9167\n",
      "Epoch 102/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.1341 - accuracy: 0.9434 - val_loss: 0.1075 - val_accuracy: 0.9583\n",
      "Epoch 103/500\n",
      "212/212 [==============================] - 0s 24us/sample - loss: 0.1326 - accuracy: 0.9434 - val_loss: 0.1065 - val_accuracy: 0.9583\n",
      "Epoch 104/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.1311 - accuracy: 0.9434 - val_loss: 0.1054 - val_accuracy: 0.9583\n",
      "Epoch 105/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.1297 - accuracy: 0.9434 - val_loss: 0.1045 - val_accuracy: 0.9583\n",
      "Epoch 106/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.1283 - accuracy: 0.9434 - val_loss: 0.1035 - val_accuracy: 0.9583\n",
      "Epoch 107/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.1269 - accuracy: 0.9434 - val_loss: 0.1026 - val_accuracy: 0.9583\n",
      "Epoch 108/500\n",
      "212/212 [==============================] - 0s 35us/sample - loss: 0.1255 - accuracy: 0.9434 - val_loss: 0.1017 - val_accuracy: 0.9583\n",
      "Epoch 109/500\n",
      "212/212 [==============================] - 0s 52us/sample - loss: 0.1242 - accuracy: 0.9434 - val_loss: 0.1008 - val_accuracy: 0.9583\n",
      "Epoch 110/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.1229 - accuracy: 0.9434 - val_loss: 0.1000 - val_accuracy: 0.9583\n",
      "Epoch 111/500\n",
      "212/212 [==============================] - 0s 37us/sample - loss: 0.1216 - accuracy: 0.9434 - val_loss: 0.0991 - val_accuracy: 0.9583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.1204 - accuracy: 0.9434 - val_loss: 0.0983 - val_accuracy: 0.9583\n",
      "Epoch 113/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.1193 - accuracy: 0.9434 - val_loss: 0.0974 - val_accuracy: 0.9583\n",
      "Epoch 114/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.1182 - accuracy: 0.9434 - val_loss: 0.0966 - val_accuracy: 0.9583\n",
      "Epoch 115/500\n",
      "212/212 [==============================] - 0s 41us/sample - loss: 0.1171 - accuracy: 0.9481 - val_loss: 0.0957 - val_accuracy: 0.9583\n",
      "Epoch 116/500\n",
      "212/212 [==============================] - 0s 34us/sample - loss: 0.1160 - accuracy: 0.9481 - val_loss: 0.0948 - val_accuracy: 0.9583\n",
      "Epoch 117/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.1150 - accuracy: 0.9481 - val_loss: 0.0941 - val_accuracy: 0.9583\n",
      "Epoch 118/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.1140 - accuracy: 0.9481 - val_loss: 0.0935 - val_accuracy: 0.9583\n",
      "Epoch 119/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.1130 - accuracy: 0.9481 - val_loss: 0.0928 - val_accuracy: 0.9583\n",
      "Epoch 120/500\n",
      "212/212 [==============================] - 0s 41us/sample - loss: 0.1121 - accuracy: 0.9481 - val_loss: 0.0921 - val_accuracy: 0.9583\n",
      "Epoch 121/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.1111 - accuracy: 0.9481 - val_loss: 0.0914 - val_accuracy: 0.9583\n",
      "Epoch 122/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.1103 - accuracy: 0.9481 - val_loss: 0.0907 - val_accuracy: 0.9583\n",
      "Epoch 123/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.1094 - accuracy: 0.9481 - val_loss: 0.0900 - val_accuracy: 0.9583\n",
      "Epoch 124/500\n",
      "212/212 [==============================] - 0s 32us/sample - loss: 0.1085 - accuracy: 0.9528 - val_loss: 0.0893 - val_accuracy: 0.9583\n",
      "Epoch 125/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.1077 - accuracy: 0.9528 - val_loss: 0.0886 - val_accuracy: 0.9583\n",
      "Epoch 126/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.1069 - accuracy: 0.9528 - val_loss: 0.0880 - val_accuracy: 0.9583\n",
      "Epoch 127/500\n",
      "212/212 [==============================] - 0s 66us/sample - loss: 0.1061 - accuracy: 0.9528 - val_loss: 0.0873 - val_accuracy: 0.9583\n",
      "Epoch 128/500\n",
      "212/212 [==============================] - 0s 56us/sample - loss: 0.1054 - accuracy: 0.9575 - val_loss: 0.0867 - val_accuracy: 0.9583\n",
      "Epoch 129/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.1047 - accuracy: 0.9575 - val_loss: 0.0861 - val_accuracy: 0.9583\n",
      "Epoch 130/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.1039 - accuracy: 0.9575 - val_loss: 0.0856 - val_accuracy: 0.9583\n",
      "Epoch 131/500\n",
      "212/212 [==============================] - 0s 44us/sample - loss: 0.1032 - accuracy: 0.9575 - val_loss: 0.0851 - val_accuracy: 0.9583\n",
      "Epoch 132/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.1025 - accuracy: 0.9575 - val_loss: 0.0847 - val_accuracy: 0.9583\n",
      "Epoch 133/500\n",
      "212/212 [==============================] - 0s 31us/sample - loss: 0.1018 - accuracy: 0.9575 - val_loss: 0.0843 - val_accuracy: 0.9583\n",
      "Epoch 134/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.1012 - accuracy: 0.9575 - val_loss: 0.0839 - val_accuracy: 0.9583\n",
      "Epoch 135/500\n",
      "212/212 [==============================] - 0s 36us/sample - loss: 0.1005 - accuracy: 0.9575 - val_loss: 0.0835 - val_accuracy: 0.9583\n",
      "Epoch 136/500\n",
      "212/212 [==============================] - 0s 43us/sample - loss: 0.0998 - accuracy: 0.9575 - val_loss: 0.0831 - val_accuracy: 0.9583\n",
      "Epoch 137/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0992 - accuracy: 0.9575 - val_loss: 0.0828 - val_accuracy: 0.9583\n",
      "Epoch 138/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0985 - accuracy: 0.9575 - val_loss: 0.0825 - val_accuracy: 0.9583\n",
      "Epoch 139/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0979 - accuracy: 0.9575 - val_loss: 0.0822 - val_accuracy: 0.9583\n",
      "Epoch 140/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0973 - accuracy: 0.9575 - val_loss: 0.0819 - val_accuracy: 0.9583\n",
      "Epoch 141/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0967 - accuracy: 0.9575 - val_loss: 0.0816 - val_accuracy: 0.9583\n",
      "Epoch 142/500\n",
      "212/212 [==============================] - 0s 45us/sample - loss: 0.0961 - accuracy: 0.9575 - val_loss: 0.0812 - val_accuracy: 0.9583\n",
      "Epoch 143/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0956 - accuracy: 0.9575 - val_loss: 0.0809 - val_accuracy: 0.9583\n",
      "Epoch 144/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0950 - accuracy: 0.9575 - val_loss: 0.0806 - val_accuracy: 0.9583\n",
      "Epoch 145/500\n",
      "212/212 [==============================] - 0s 46us/sample - loss: 0.0944 - accuracy: 0.9575 - val_loss: 0.0803 - val_accuracy: 0.9583\n",
      "Epoch 146/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0938 - accuracy: 0.9575 - val_loss: 0.0800 - val_accuracy: 0.9583\n",
      "Epoch 147/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0933 - accuracy: 0.9575 - val_loss: 0.0797 - val_accuracy: 0.9583\n",
      "Epoch 148/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0928 - accuracy: 0.9575 - val_loss: 0.0794 - val_accuracy: 0.9583\n",
      "Epoch 149/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0922 - accuracy: 0.9575 - val_loss: 0.0791 - val_accuracy: 0.9583\n",
      "Epoch 150/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0917 - accuracy: 0.9575 - val_loss: 0.0788 - val_accuracy: 0.9583\n",
      "Epoch 151/500\n",
      "212/212 [==============================] - 0s 56us/sample - loss: 0.0911 - accuracy: 0.9575 - val_loss: 0.0785 - val_accuracy: 0.9583\n",
      "Epoch 152/500\n",
      "212/212 [==============================] - 0s 48us/sample - loss: 0.0906 - accuracy: 0.9575 - val_loss: 0.0783 - val_accuracy: 0.9583\n",
      "Epoch 153/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0901 - accuracy: 0.9575 - val_loss: 0.0780 - val_accuracy: 0.9583\n",
      "Epoch 154/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0896 - accuracy: 0.9575 - val_loss: 0.0777 - val_accuracy: 0.9583\n",
      "Epoch 155/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0890 - accuracy: 0.9575 - val_loss: 0.0774 - val_accuracy: 0.9583\n",
      "Epoch 156/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0885 - accuracy: 0.9575 - val_loss: 0.0772 - val_accuracy: 0.9583\n",
      "Epoch 157/500\n",
      "212/212 [==============================] - 0s 41us/sample - loss: 0.0880 - accuracy: 0.9575 - val_loss: 0.0769 - val_accuracy: 0.9583\n",
      "Epoch 158/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0875 - accuracy: 0.9575 - val_loss: 0.0766 - val_accuracy: 0.9583\n",
      "Epoch 159/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0870 - accuracy: 0.9575 - val_loss: 0.0763 - val_accuracy: 0.9583\n",
      "Epoch 160/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0865 - accuracy: 0.9575 - val_loss: 0.0759 - val_accuracy: 0.9583\n",
      "Epoch 161/500\n",
      "212/212 [==============================] - 0s 56us/sample - loss: 0.0860 - accuracy: 0.9575 - val_loss: 0.0756 - val_accuracy: 0.9583\n",
      "Epoch 162/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0855 - accuracy: 0.9575 - val_loss: 0.0753 - val_accuracy: 0.9583\n",
      "Epoch 163/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0851 - accuracy: 0.9575 - val_loss: 0.0750 - val_accuracy: 0.9583\n",
      "Epoch 164/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0846 - accuracy: 0.9575 - val_loss: 0.0747 - val_accuracy: 0.9583\n",
      "Epoch 165/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0841 - accuracy: 0.9575 - val_loss: 0.0744 - val_accuracy: 0.9583\n",
      "Epoch 166/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0836 - accuracy: 0.9575 - val_loss: 0.0742 - val_accuracy: 0.9583\n",
      "Epoch 167/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0831 - accuracy: 0.9575 - val_loss: 0.0739 - val_accuracy: 0.9583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0827 - accuracy: 0.9575 - val_loss: 0.0736 - val_accuracy: 0.9583\n",
      "Epoch 169/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0822 - accuracy: 0.9575 - val_loss: 0.0734 - val_accuracy: 0.9583\n",
      "Epoch 170/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0817 - accuracy: 0.9575 - val_loss: 0.0731 - val_accuracy: 0.9583\n",
      "Epoch 171/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0813 - accuracy: 0.9575 - val_loss: 0.0728 - val_accuracy: 0.9583\n",
      "Epoch 172/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0808 - accuracy: 0.9575 - val_loss: 0.0725 - val_accuracy: 0.9583\n",
      "Epoch 173/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0804 - accuracy: 0.9575 - val_loss: 0.0722 - val_accuracy: 0.9583\n",
      "Epoch 174/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0799 - accuracy: 0.9575 - val_loss: 0.0719 - val_accuracy: 0.9583\n",
      "Epoch 175/500\n",
      "212/212 [==============================] - 0s 52us/sample - loss: 0.0795 - accuracy: 0.9575 - val_loss: 0.0716 - val_accuracy: 0.9583\n",
      "Epoch 176/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0790 - accuracy: 0.9575 - val_loss: 0.0713 - val_accuracy: 0.9583\n",
      "Epoch 177/500\n",
      "212/212 [==============================] - 0s 40us/sample - loss: 0.0786 - accuracy: 0.9575 - val_loss: 0.0710 - val_accuracy: 0.9583\n",
      "Epoch 178/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0782 - accuracy: 0.9575 - val_loss: 0.0707 - val_accuracy: 0.9583\n",
      "Epoch 179/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0777 - accuracy: 0.9575 - val_loss: 0.0705 - val_accuracy: 0.9583\n",
      "Epoch 180/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0773 - accuracy: 0.9575 - val_loss: 0.0702 - val_accuracy: 0.9583\n",
      "Epoch 181/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0769 - accuracy: 0.9575 - val_loss: 0.0699 - val_accuracy: 0.9583\n",
      "Epoch 182/500\n",
      "212/212 [==============================] - 0s 37us/sample - loss: 0.0765 - accuracy: 0.9575 - val_loss: 0.0696 - val_accuracy: 0.9583\n",
      "Epoch 183/500\n",
      "212/212 [==============================] - 0s 52us/sample - loss: 0.0761 - accuracy: 0.9575 - val_loss: 0.0693 - val_accuracy: 0.9583\n",
      "Epoch 184/500\n",
      "212/212 [==============================] - 0s 43us/sample - loss: 0.0756 - accuracy: 0.9623 - val_loss: 0.0691 - val_accuracy: 0.9583\n",
      "Epoch 185/500\n",
      "212/212 [==============================] - 0s 39us/sample - loss: 0.0752 - accuracy: 0.9623 - val_loss: 0.0688 - val_accuracy: 0.9583\n",
      "Epoch 186/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0748 - accuracy: 0.9670 - val_loss: 0.0685 - val_accuracy: 0.9583\n",
      "Epoch 187/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0744 - accuracy: 0.9670 - val_loss: 0.0683 - val_accuracy: 0.9583\n",
      "Epoch 188/500\n",
      "212/212 [==============================] - 0s 46us/sample - loss: 0.0740 - accuracy: 0.9670 - val_loss: 0.0680 - val_accuracy: 0.9583\n",
      "Epoch 189/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0736 - accuracy: 0.9670 - val_loss: 0.0677 - val_accuracy: 0.9583\n",
      "Epoch 190/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0732 - accuracy: 0.9670 - val_loss: 0.0675 - val_accuracy: 0.9583\n",
      "Epoch 191/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0728 - accuracy: 0.9670 - val_loss: 0.0672 - val_accuracy: 0.9583\n",
      "Epoch 192/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0724 - accuracy: 0.9670 - val_loss: 0.0670 - val_accuracy: 0.9583\n",
      "Epoch 193/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0721 - accuracy: 0.9670 - val_loss: 0.0667 - val_accuracy: 0.9583\n",
      "Epoch 194/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0717 - accuracy: 0.9670 - val_loss: 0.0664 - val_accuracy: 0.9583\n",
      "Epoch 195/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0713 - accuracy: 0.9670 - val_loss: 0.0662 - val_accuracy: 0.9583\n",
      "Epoch 196/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0710 - accuracy: 0.9670 - val_loss: 0.0659 - val_accuracy: 0.9583\n",
      "Epoch 197/500\n",
      "212/212 [==============================] - 0s 71us/sample - loss: 0.0706 - accuracy: 0.9670 - val_loss: 0.0657 - val_accuracy: 0.9583\n",
      "Epoch 198/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0703 - accuracy: 0.9670 - val_loss: 0.0655 - val_accuracy: 0.9583\n",
      "Epoch 199/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0699 - accuracy: 0.9670 - val_loss: 0.0652 - val_accuracy: 0.9583\n",
      "Epoch 200/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0696 - accuracy: 0.9670 - val_loss: 0.0650 - val_accuracy: 0.9583\n",
      "Epoch 201/500\n",
      "212/212 [==============================] - 0s 43us/sample - loss: 0.0692 - accuracy: 0.9670 - val_loss: 0.0647 - val_accuracy: 0.9583\n",
      "Epoch 202/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0689 - accuracy: 0.9670 - val_loss: 0.0645 - val_accuracy: 0.9583\n",
      "Epoch 203/500\n",
      "212/212 [==============================] - 0s 52us/sample - loss: 0.0685 - accuracy: 0.9670 - val_loss: 0.0642 - val_accuracy: 0.9583\n",
      "Epoch 204/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0682 - accuracy: 0.9670 - val_loss: 0.0640 - val_accuracy: 0.9583\n",
      "Epoch 205/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0678 - accuracy: 0.9670 - val_loss: 0.0637 - val_accuracy: 0.9583\n",
      "Epoch 206/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0675 - accuracy: 0.9670 - val_loss: 0.0635 - val_accuracy: 0.9583\n",
      "Epoch 207/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0672 - accuracy: 0.9670 - val_loss: 0.0632 - val_accuracy: 0.9583\n",
      "Epoch 208/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0668 - accuracy: 0.9717 - val_loss: 0.0630 - val_accuracy: 0.9583\n",
      "Epoch 209/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0665 - accuracy: 0.9717 - val_loss: 0.0628 - val_accuracy: 0.9583\n",
      "Epoch 210/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0661 - accuracy: 0.9717 - val_loss: 0.0626 - val_accuracy: 0.9583\n",
      "Epoch 211/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0658 - accuracy: 0.9717 - val_loss: 0.0623 - val_accuracy: 0.9583\n",
      "Epoch 212/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0655 - accuracy: 0.9717 - val_loss: 0.0621 - val_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0651 - accuracy: 0.9717 - val_loss: 0.0618 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0648 - accuracy: 0.9717 - val_loss: 0.0616 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0645 - accuracy: 0.9717 - val_loss: 0.0613 - val_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "212/212 [==============================] - 0s 37us/sample - loss: 0.0641 - accuracy: 0.9717 - val_loss: 0.0610 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0638 - accuracy: 0.9717 - val_loss: 0.0608 - val_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0635 - accuracy: 0.9717 - val_loss: 0.0605 - val_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0631 - accuracy: 0.9717 - val_loss: 0.0602 - val_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0628 - accuracy: 0.9717 - val_loss: 0.0599 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0625 - accuracy: 0.9717 - val_loss: 0.0596 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0622 - accuracy: 0.9717 - val_loss: 0.0594 - val_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0618 - accuracy: 0.9717 - val_loss: 0.0592 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0615 - accuracy: 0.9717 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0612 - accuracy: 0.9764 - val_loss: 0.0588 - val_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0609 - accuracy: 0.9764 - val_loss: 0.0586 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0605 - accuracy: 0.9764 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0602 - accuracy: 0.9764 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0599 - accuracy: 0.9764 - val_loss: 0.0579 - val_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0596 - accuracy: 0.9764 - val_loss: 0.0576 - val_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0593 - accuracy: 0.9764 - val_loss: 0.0573 - val_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0590 - accuracy: 0.9764 - val_loss: 0.0570 - val_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0587 - accuracy: 0.9764 - val_loss: 0.0567 - val_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0584 - accuracy: 0.9764 - val_loss: 0.0565 - val_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "212/212 [==============================] - 0s 56us/sample - loss: 0.0581 - accuracy: 0.9764 - val_loss: 0.0562 - val_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0578 - accuracy: 0.9764 - val_loss: 0.0560 - val_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0575 - accuracy: 0.9764 - val_loss: 0.0558 - val_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0572 - accuracy: 0.9764 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0570 - accuracy: 0.9764 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0567 - accuracy: 0.9764 - val_loss: 0.0550 - val_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "212/212 [==============================] - 0s 37us/sample - loss: 0.0564 - accuracy: 0.9764 - val_loss: 0.0547 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0562 - accuracy: 0.9764 - val_loss: 0.0544 - val_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0559 - accuracy: 0.9764 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "212/212 [==============================] - 0s 52us/sample - loss: 0.0557 - accuracy: 0.9764 - val_loss: 0.0538 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0554 - accuracy: 0.9764 - val_loss: 0.0536 - val_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0552 - accuracy: 0.9764 - val_loss: 0.0533 - val_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0549 - accuracy: 0.9764 - val_loss: 0.0531 - val_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0547 - accuracy: 0.9764 - val_loss: 0.0529 - val_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0544 - accuracy: 0.9764 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0542 - accuracy: 0.9764 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0539 - accuracy: 0.9764 - val_loss: 0.0523 - val_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "212/212 [==============================] - 0s 39us/sample - loss: 0.0537 - accuracy: 0.9764 - val_loss: 0.0520 - val_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0535 - accuracy: 0.9764 - val_loss: 0.0517 - val_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "212/212 [==============================] - 0s 43us/sample - loss: 0.0532 - accuracy: 0.9764 - val_loss: 0.0514 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0530 - accuracy: 0.9764 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0528 - accuracy: 0.9764 - val_loss: 0.0509 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0525 - accuracy: 0.9764 - val_loss: 0.0507 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0523 - accuracy: 0.9764 - val_loss: 0.0504 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0521 - accuracy: 0.9764 - val_loss: 0.0502 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0519 - accuracy: 0.9764 - val_loss: 0.0500 - val_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0516 - accuracy: 0.9764 - val_loss: 0.0498 - val_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "212/212 [==============================] - 0s 43us/sample - loss: 0.0514 - accuracy: 0.9764 - val_loss: 0.0496 - val_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0512 - accuracy: 0.9764 - val_loss: 0.0494 - val_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "212/212 [==============================] - 0s 49us/sample - loss: 0.0510 - accuracy: 0.9764 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "212/212 [==============================] - 0s 52us/sample - loss: 0.0507 - accuracy: 0.9764 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0505 - accuracy: 0.9764 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "212/212 [==============================] - 0s 66us/sample - loss: 0.0503 - accuracy: 0.9764 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0501 - accuracy: 0.9764 - val_loss: 0.0482 - val_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "212/212 [==============================] - 0s 37us/sample - loss: 0.0499 - accuracy: 0.9764 - val_loss: 0.0480 - val_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0496 - accuracy: 0.9811 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0494 - accuracy: 0.9811 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0492 - accuracy: 0.9811 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0490 - accuracy: 0.9811 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0488 - accuracy: 0.9811 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0486 - accuracy: 0.9811 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "212/212 [==============================] - 0s 113us/sample - loss: 0.0484 - accuracy: 0.9811 - val_loss: 0.0466 - val_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "212/212 [==============================] - 0s 56us/sample - loss: 0.0481 - accuracy: 0.9811 - val_loss: 0.0463 - val_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "212/212 [==============================] - 0s 56us/sample - loss: 0.0479 - accuracy: 0.9811 - val_loss: 0.0460 - val_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0477 - accuracy: 0.9811 - val_loss: 0.0458 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/500\n",
      "212/212 [==============================] - 0s 54us/sample - loss: 0.0475 - accuracy: 0.9811 - val_loss: 0.0455 - val_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0473 - accuracy: 0.9811 - val_loss: 0.0453 - val_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "212/212 [==============================] - 0s 43us/sample - loss: 0.0471 - accuracy: 0.9811 - val_loss: 0.0451 - val_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0469 - accuracy: 0.9811 - val_loss: 0.0449 - val_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0467 - accuracy: 0.9811 - val_loss: 0.0446 - val_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "212/212 [==============================] - 0s 41us/sample - loss: 0.0465 - accuracy: 0.9811 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0463 - accuracy: 0.9811 - val_loss: 0.0441 - val_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0461 - accuracy: 0.9811 - val_loss: 0.0438 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0459 - accuracy: 0.9811 - val_loss: 0.0436 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0457 - accuracy: 0.9811 - val_loss: 0.0434 - val_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0455 - accuracy: 0.9811 - val_loss: 0.0432 - val_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0453 - accuracy: 0.9811 - val_loss: 0.0429 - val_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "212/212 [==============================] - 0s 51us/sample - loss: 0.0451 - accuracy: 0.9811 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "212/212 [==============================] - 0s 46us/sample - loss: 0.0450 - accuracy: 0.9811 - val_loss: 0.0425 - val_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0448 - accuracy: 0.9811 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0446 - accuracy: 0.9811 - val_loss: 0.0421 - val_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0445 - accuracy: 0.9811 - val_loss: 0.0418 - val_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0443 - accuracy: 0.9811 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0441 - accuracy: 0.9811 - val_loss: 0.0414 - val_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0440 - accuracy: 0.9811 - val_loss: 0.0412 - val_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0438 - accuracy: 0.9811 - val_loss: 0.0410 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "212/212 [==============================] - 0s 37us/sample - loss: 0.0436 - accuracy: 0.9811 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0435 - accuracy: 0.9811 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "212/212 [==============================] - 0s 36us/sample - loss: 0.0433 - accuracy: 0.9811 - val_loss: 0.0404 - val_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "212/212 [==============================] - 0s 31us/sample - loss: 0.0432 - accuracy: 0.9811 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0430 - accuracy: 0.9811 - val_loss: 0.0401 - val_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0428 - accuracy: 0.9811 - val_loss: 0.0399 - val_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0427 - accuracy: 0.9811 - val_loss: 0.0398 - val_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "212/212 [==============================] - 0s 43us/sample - loss: 0.0425 - accuracy: 0.9811 - val_loss: 0.0397 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0424 - accuracy: 0.9811 - val_loss: 0.0395 - val_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0422 - accuracy: 0.9811 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0421 - accuracy: 0.9811 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "212/212 [==============================] - 0s 75us/sample - loss: 0.0419 - accuracy: 0.9811 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "212/212 [==============================] - 0s 52us/sample - loss: 0.0417 - accuracy: 0.9811 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "212/212 [==============================] - 0s 53us/sample - loss: 0.0416 - accuracy: 0.9811 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0414 - accuracy: 0.9811 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0413 - accuracy: 0.9811 - val_loss: 0.0384 - val_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0411 - accuracy: 0.9811 - val_loss: 0.0382 - val_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0410 - accuracy: 0.9811 - val_loss: 0.0380 - val_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0408 - accuracy: 0.9811 - val_loss: 0.0379 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0407 - accuracy: 0.9811 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0405 - accuracy: 0.9811 - val_loss: 0.0376 - val_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "212/212 [==============================] - 0s 43us/sample - loss: 0.0404 - accuracy: 0.9811 - val_loss: 0.0374 - val_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "212/212 [==============================] - 0s 46us/sample - loss: 0.0402 - accuracy: 0.9811 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0401 - accuracy: 0.9811 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0399 - accuracy: 0.9811 - val_loss: 0.0369 - val_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0398 - accuracy: 0.9811 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0396 - accuracy: 0.9811 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0395 - accuracy: 0.9811 - val_loss: 0.0363 - val_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0394 - accuracy: 0.9811 - val_loss: 0.0360 - val_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0393 - accuracy: 0.9811 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0391 - accuracy: 0.9811 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "212/212 [==============================] - 0s 43us/sample - loss: 0.0390 - accuracy: 0.9811 - val_loss: 0.0353 - val_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0389 - accuracy: 0.9811 - val_loss: 0.0352 - val_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0388 - accuracy: 0.9811 - val_loss: 0.0350 - val_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "212/212 [==============================] - 0s 41us/sample - loss: 0.0387 - accuracy: 0.9858 - val_loss: 0.0349 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0385 - accuracy: 0.9858 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0384 - accuracy: 0.9858 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0383 - accuracy: 0.9858 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0382 - accuracy: 0.9858 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0381 - accuracy: 0.9858 - val_loss: 0.0339 - val_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0380 - accuracy: 0.9858 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0379 - accuracy: 0.9858 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0378 - accuracy: 0.9858 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0376 - accuracy: 0.9858 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0375 - accuracy: 0.9858 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0374 - accuracy: 0.9858 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0373 - accuracy: 0.9858 - val_loss: 0.0326 - val_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0372 - accuracy: 0.9858 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0371 - accuracy: 0.9858 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0370 - accuracy: 0.9858 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "212/212 [==============================] - 0s 56us/sample - loss: 0.0369 - accuracy: 0.9858 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "212/212 [==============================] - 0s 61us/sample - loss: 0.0368 - accuracy: 0.9858 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0367 - accuracy: 0.9858 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0366 - accuracy: 0.9858 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0365 - accuracy: 0.9858 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0365 - accuracy: 0.9858 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "212/212 [==============================] - 0s 43us/sample - loss: 0.0364 - accuracy: 0.9858 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0363 - accuracy: 0.9858 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0362 - accuracy: 0.9858 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0361 - accuracy: 0.9858 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "212/212 [==============================] - 0s 43us/sample - loss: 0.0360 - accuracy: 0.9858 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "212/212 [==============================] - 0s 39us/sample - loss: 0.0359 - accuracy: 0.9858 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0358 - accuracy: 0.9858 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0358 - accuracy: 0.9858 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0357 - accuracy: 0.9858 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "212/212 [==============================] - 0s 56us/sample - loss: 0.0356 - accuracy: 0.9858 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0355 - accuracy: 0.9858 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "212/212 [==============================] - 0s 46us/sample - loss: 0.0354 - accuracy: 0.9858 - val_loss: 0.0297 - val_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0353 - accuracy: 0.9858 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0352 - accuracy: 0.9858 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0351 - accuracy: 0.9858 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0351 - accuracy: 0.9858 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "212/212 [==============================] - 0s 48us/sample - loss: 0.0350 - accuracy: 0.9858 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0349 - accuracy: 0.9858 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "212/212 [==============================] - 0s 29us/sample - loss: 0.0348 - accuracy: 0.9858 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "212/212 [==============================] - 0s 41us/sample - loss: 0.0347 - accuracy: 0.9858 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0346 - accuracy: 0.9858 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "212/212 [==============================] - 0s 74us/sample - loss: 0.0345 - accuracy: 0.9858 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "212/212 [==============================] - 0s 29us/sample - loss: 0.0345 - accuracy: 0.9858 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "212/212 [==============================] - 0s 24us/sample - loss: 0.0344 - accuracy: 0.9858 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0343 - accuracy: 0.9858 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "212/212 [==============================] - 0s 40us/sample - loss: 0.0342 - accuracy: 0.9858 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0341 - accuracy: 0.9858 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0340 - accuracy: 0.9858 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0340 - accuracy: 0.9858 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0339 - accuracy: 0.9858 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0338 - accuracy: 0.9858 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0337 - accuracy: 0.9858 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0336 - accuracy: 0.9858 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0335 - accuracy: 0.9858 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0334 - accuracy: 0.9858 - val_loss: 0.0273 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0334 - accuracy: 0.9858 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0333 - accuracy: 0.9858 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0332 - accuracy: 0.9858 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0331 - accuracy: 0.9858 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0330 - accuracy: 0.9858 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "212/212 [==============================] - 0s 43us/sample - loss: 0.0329 - accuracy: 0.9858 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0328 - accuracy: 0.9858 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0328 - accuracy: 0.9858 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0327 - accuracy: 0.9858 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "212/212 [==============================] - 0s 52us/sample - loss: 0.0326 - accuracy: 0.9858 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "212/212 [==============================] - 0s 37us/sample - loss: 0.0325 - accuracy: 0.9858 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "212/212 [==============================] - 0s 50us/sample - loss: 0.0324 - accuracy: 0.9858 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0323 - accuracy: 0.9858 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "212/212 [==============================] - 0s 43us/sample - loss: 0.0323 - accuracy: 0.9858 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0322 - accuracy: 0.9858 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "212/212 [==============================] - 0s 36us/sample - loss: 0.0321 - accuracy: 0.9858 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0320 - accuracy: 0.9858 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "212/212 [==============================] - 0s 48us/sample - loss: 0.0319 - accuracy: 0.9858 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0318 - accuracy: 0.9858 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0318 - accuracy: 0.9858 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0317 - accuracy: 0.9858 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "212/212 [==============================] - 0s 24us/sample - loss: 0.0316 - accuracy: 0.9858 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "212/212 [==============================] - 0s 39us/sample - loss: 0.0315 - accuracy: 0.9858 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0314 - accuracy: 0.9858 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "212/212 [==============================] - 0s 45us/sample - loss: 0.0313 - accuracy: 0.9858 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0313 - accuracy: 0.9858 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0312 - accuracy: 0.9858 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "212/212 [==============================] - 0s 71us/sample - loss: 0.0311 - accuracy: 0.9858 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0310 - accuracy: 0.9858 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0309 - accuracy: 0.9858 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0308 - accuracy: 0.9858 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "212/212 [==============================] - 0s 56us/sample - loss: 0.0308 - accuracy: 0.9858 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "212/212 [==============================] - 0s 34us/sample - loss: 0.0307 - accuracy: 0.9858 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0306 - accuracy: 0.9858 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0305 - accuracy: 0.9858 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0304 - accuracy: 0.9858 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0303 - accuracy: 0.9858 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0303 - accuracy: 0.9858 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "212/212 [==============================] - 0s 31us/sample - loss: 0.0302 - accuracy: 0.9858 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "212/212 [==============================] - 0s 29us/sample - loss: 0.0301 - accuracy: 0.9858 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0300 - accuracy: 0.9858 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0299 - accuracy: 0.9858 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "212/212 [==============================] - 0s 32us/sample - loss: 0.0299 - accuracy: 0.9858 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0298 - accuracy: 0.9858 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "212/212 [==============================] - 0s 26us/sample - loss: 0.0297 - accuracy: 0.9858 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0296 - accuracy: 0.9858 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "212/212 [==============================] - 0s 30us/sample - loss: 0.0295 - accuracy: 0.9858 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "212/212 [==============================] - 0s 37us/sample - loss: 0.0295 - accuracy: 0.9858 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0294 - accuracy: 0.9858 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "212/212 [==============================] - 0s 65us/sample - loss: 0.0293 - accuracy: 0.9858 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0292 - accuracy: 0.9858 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "212/212 [==============================] - 0s 27us/sample - loss: 0.0291 - accuracy: 0.9858 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0291 - accuracy: 0.9858 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0290 - accuracy: 0.9858 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0289 - accuracy: 0.9858 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0288 - accuracy: 0.9858 - val_loss: 0.0204 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/500\n",
      "212/212 [==============================] - 0s 132us/sample - loss: 0.0287 - accuracy: 0.9858 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "212/212 [==============================] - 0s 56us/sample - loss: 0.0287 - accuracy: 0.9858 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0286 - accuracy: 0.9858 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0285 - accuracy: 0.9906 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0284 - accuracy: 0.9906 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0284 - accuracy: 0.9906 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "212/212 [==============================] - 0s 41us/sample - loss: 0.0283 - accuracy: 0.9906 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "212/212 [==============================] - 0s 52us/sample - loss: 0.0282 - accuracy: 0.9906 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0281 - accuracy: 0.9906 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0280 - accuracy: 0.9906 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0280 - accuracy: 0.9906 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "212/212 [==============================] - 0s 24us/sample - loss: 0.0279 - accuracy: 0.9906 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0278 - accuracy: 0.9906 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "212/212 [==============================] - 0s 23us/sample - loss: 0.0277 - accuracy: 0.9906 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "212/212 [==============================] - 0s 32us/sample - loss: 0.0277 - accuracy: 0.9906 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0276 - accuracy: 0.9906 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0275 - accuracy: 0.9906 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "212/212 [==============================] - 0s 32us/sample - loss: 0.0274 - accuracy: 0.9906 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0273 - accuracy: 0.9906 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0273 - accuracy: 0.9906 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "212/212 [==============================] - 0s 37us/sample - loss: 0.0272 - accuracy: 0.9906 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0271 - accuracy: 0.9906 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "212/212 [==============================] - 0s 30us/sample - loss: 0.0270 - accuracy: 0.9906 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0270 - accuracy: 0.9906 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0269 - accuracy: 0.9906 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "212/212 [==============================] - 0s 29us/sample - loss: 0.0268 - accuracy: 0.9906 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0267 - accuracy: 0.9906 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "212/212 [==============================] - 0s 27us/sample - loss: 0.0267 - accuracy: 0.9906 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0266 - accuracy: 0.9906 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0265 - accuracy: 0.9906 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "212/212 [==============================] - 0s 52us/sample - loss: 0.0264 - accuracy: 0.9906 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0263 - accuracy: 0.9906 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0263 - accuracy: 0.9906 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "212/212 [==============================] - 0s 27us/sample - loss: 0.0262 - accuracy: 0.9906 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "212/212 [==============================] - 0s 23us/sample - loss: 0.0261 - accuracy: 0.9906 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0261 - accuracy: 0.9906 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "212/212 [==============================] - 0s 37us/sample - loss: 0.0260 - accuracy: 0.9906 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "212/212 [==============================] - 0s 24us/sample - loss: 0.0259 - accuracy: 0.9906 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0259 - accuracy: 0.9906 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "212/212 [==============================] - 0s 29us/sample - loss: 0.0258 - accuracy: 0.9906 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0257 - accuracy: 0.9906 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0257 - accuracy: 0.9906 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "212/212 [==============================] - 0s 28us/sample - loss: 0.0256 - accuracy: 0.9906 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "212/212 [==============================] - 0s 38us/sample - loss: 0.0255 - accuracy: 0.9906 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "212/212 [==============================] - 0s 24us/sample - loss: 0.0255 - accuracy: 0.9906 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "212/212 [==============================] - 0s 33us/sample - loss: 0.0254 - accuracy: 0.9906 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0253 - accuracy: 0.9906 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "212/212 [==============================] - 0s 25us/sample - loss: 0.0253 - accuracy: 0.9906 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "212/212 [==============================] - 0s 56us/sample - loss: 0.0252 - accuracy: 0.9906 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "212/212 [==============================] - 0s 47us/sample - loss: 0.0251 - accuracy: 0.9906 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "212/212 [==============================] - 0s 42us/sample - loss: 0.0251 - accuracy: 0.9906 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "212/212 [==============================] - 0s 27us/sample - loss: 0.0250 - accuracy: 0.9906 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "212/212 [==============================] - 0s 22us/sample - loss: 0.0249 - accuracy: 0.9906 - val_loss: 0.0137 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500, batch_size=X_train.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programs\\Miniconda3\\envs\\qualirede\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ckd.model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(\"ckd.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the model loss\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('accuracy and loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the model accuracy\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy and loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Shape of training data:  (212, 9)\n",
      "Shape of test data    :  (24, 9)\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------------------------------\")\n",
    "print(\"Shape of training data: \", X_train.shape)\n",
    "print(\"Shape of test data    : \", X_test.shape )\n",
    "print(\"---------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file:  ckd.model\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "24/24 [==============================] - 0s 9ms/sample - loss: 0.0137 - accuracy: 1.0000\n",
      "\n",
      "Original  : 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0\n",
      "\n",
      "Predicted : 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0\n",
      "\n",
      "Scores    : loss =  0.013665661215782166  acc =  1.0\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_file in glob.glob(\"*.model\"):\n",
    "    print(\"Model file: \", model_file)\n",
    "    model = load_model(model_file)\n",
    "    pred = model.predict(X_test)\n",
    "    pred = [1 if y>=0.5 else 0 for y in pred] #Threshold, transforming probabilities to either 0 or 1 depending if the probability is below or above 0.5\n",
    "    scores = model.evaluate(X_test, y_test)\n",
    "    print()\n",
    "    print(\"Original  : {0}\".format(\", \".join([str(x) for x in y_test])))\n",
    "    print()\n",
    "    print(\"Predicted : {0}\".format(\", \".join([str(x) for x in pred])))\n",
    "    print() \n",
    "    print(\"Scores    : loss = \", scores[0], \" acc = \", scores[1])\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
